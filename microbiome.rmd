---
title: "microbiome"
author: "Tsunghan Hsieh"
date: "2023-01-14"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Workflow for Microbiome Data Analysis

This is a tutorial document for microbiome data analysis. Credit: <https://bioconductor.org/help/course-materials/2017/BioC2017/Day1/Workshops/Microbiome/MicrobiomeWorkflowII.html#construct_phylogenetic_tree>.

## Packages

```{r packages}
library("knitr")
library("BiocStyle")
.cran_packages <- c("ggplot2", "gridExtra")
.bioc_packages <- c("dada2", "phyloseq", "DECIPHER", "phangorn")
.inst <- .cran_packages %in% installed.packages()
if(any(!.inst)) {
   install.packages(.cran_packages[!.inst])
}
.inst <- .bioc_packages %in% installed.packages()
if(any(!.inst)) {
  if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
  BiocManager::install(.bioc_packages[!.inst], ask = F)
}
# Load packages into session, and print package version
sapply(c(.cran_packages, .bioc_packages), require, character.only = TRUE)
```
## Input data
```{r input_data}
set.seed(1234) # make sure the random sampling data could be replicated in each time
wd_path <- "/Users/hsieh/Microbiome"
miseq_path <- "/Users/hsieh/Microbiome/Data/MiSeq_SOP"
meta <- "MIMARKS_Data_combined.csv"
list.files(miseq_path)
```

## Filter and Trim
### Check data
```{r check_data}
# Sort ensures forward/reverse reads are in same order
fnFs <- sort(list.files(miseq_path, pattern="_R1_001.fastq"))
fnRs <- sort(list.files(miseq_path, pattern="_R2_001.fastq"))

# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sampleNames <- sapply(strsplit(fnFs, "_"), `[`, 1)

# Specify the full path to the fnFs and fnRs
fnFs <- file.path(miseq_path, fnFs)
fnRs <- file.path(miseq_path, fnRs)
fnFs[1:3]
fnRs[1:3]
```

### plot the quality of forward and reverse data
```{r plot_quality, echo=FALSE}
plotQualityProfile(fnFs[1:2]) # after 240, the quality drops
```
```{r plot_quality, echo=FALSE}
plotQualityProfile(fnRs[1:2]) # after 160, the quality drops
```

### Filtering
```{r filtering}
# Generate filtered file names
filt_path <- file.path(miseq_path, "filtered") # Place filtered files in filtered/ subdirectory
if(!file_test("-d", filt_path)) dir.create(filt_path)
filtFs <- file.path(filt_path, paste0(sampleNames, "_F_filt.fastq.gz"))
filtRs <- file.path(filt_path, paste0(sampleNames, "_R_filt.fastq.gz"))

out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(240,160),
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
head(out)
```

## Infer sequence variants
The basic idea of 16S rRNA sequence analysis is to compare the differences of 16S rRNA sequence between each sample and assign a taxonomy name to the sample. However, errors occurred during sequencing process could wrongly give the sample different taxonomy name. Therefore, we should first calculate the error rate among the whole experiments and set the threshold for excluding sequences with too many errors.

### Dereplication
```{r dereplication}
derepFs <- derepFastq(filtFs, verbose=TRUE)
derepRs <- derepFastq(filtRs, verbose=TRUE)
# Name the derep-class objects by the sample names
names(derepFs) <- sampleNames
names(derepRs) <- sampleNames
```

### Learn error rates (Learn from forward and reverse separately)
```{r learn_err}
errF <- learnErrors(filtFs, multithread=TRUE)
errR <- learnErrors(filtRs, multithread=TRUE)
```

### Plot the error rates
```{r plot}
plotErrors(errF)
plotErrors(errR)
```
### Denoise
The DADA2 sequence inference method can run in two different modes: Independent inference by sample (pool=FALSE), and inference from the pooled sequencing reads from all samples (pool=TRUE). Independent inference has the advantage that computation time is linear in the number of samples, and memory requirements are flat with the number of samples. This allows scaling out to datasets of almost unlimited size. Pooled inference is more computationally taxing, and can become intractable for datasets of tens of millions of reads. However, pooling improves the detection of rare variants that were seen just once or twice in an individual sample but many times across all samples. As this dataset is not particularly large, we perform pooled inference. As of version 1.2, multithreading can now be activated with the arguments multithread = TRUE, which substantially speeds this step.
```{r denoise}
# When data amount becomes large, don't pool sample and use independent inference
dadaFs <- dada(derepFs, err=errF, multithread=TRUE)
dadaRs <- dada(derepRs, err=errR, multithread=TRUE)

# The final output
dadaFs[[1]]
```

## Construct sequence table and remove chimeras
### Construct sequence table
```{r merge_pairs}
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs) # Combine F+R reads and count
seqtabAll <- makeSequenceTable(mergers[!grepl("Mock", names(mergers))]) # Generate Sequence-sample count matrix
table(nchar(getSequences(seqtabAll)))
```

### Remove chimeras
```{r remove_chimeras}
seqtabNoC <- removeBimeraDenovo(seqtabAll)
```

## Assign Toxonomy
The classifier first take the training data set and develop a model to classify our target data set. We use [rdp_train_set_16.fa.gz](https://zenodo.org/record/801828#.Y8JOEOzMLt0) as our training set. Sequences with 97% identity to the target Toxonomy are assigned to it.
```{r training}
fastaRef <- file.path(wd_path,"./rdp_train_set_16.fa.gz")
taxTab <- assignTaxonomy(seqtabNoC, refFasta = fastaRef, multithread=TRUE)
unname(head(taxTab))
```

## Constuct phylogenetic tree
### Perform multiple pair-wise alignments
```{r pairwise_alignment}
# Perform pair-wise alignment
seqs <- getSequences(seqtabNoC)
names(seqs) <- seqs # This propagates to the tip labels of the tree
alignment <- AlignSeqs(DNAStringSet(seqs), anchor=NA,verbose=FALSE)
```

### Construct tree
```{r construct_tree}
# Construct phylogenetic tree
phangAlign <- phyDat(as(alignment, "matrix"), type="DNA")
dm <- dist.ml(phangAlign)
treeNJ <- NJ(dm) # Note, tip order != sequence order
fit = pml(treeNJ, data=phangAlign)
fitGTR <- update(fit, k=4, inv=0.2)
fitGTR <- optim.pml(fitGTR, model="GTR", optInv=TRUE, optGamma=TRUE,
        rearrangement = "stochastic", control = pml.control(trace = 0))
detach("package:phangorn", unload=TRUE)
```

### Combine meta data with tree
Get [Meta data](https://raw.githubusercontent.com/spholmes/F1000_workflow/master/data/MIMARKS_Data_combined.csv).
```{r combine_meta_tree}
# Read and clean the meta data
samdf <- read.csv(file.path(wd_path,meta),header=TRUE)
samdf$SampleID <- paste0(gsub("00", "", samdf$host_subject_id), "D", samdf$age-21)
samdf <- samdf[!duplicated(samdf$SampleID),] # Remove dupicate entries for reverse reads
rownames(seqtabAll) <- gsub("124", "125", rownames(seqtabAll)) # Fix discrepancy
all(rownames(seqtabAll) %in% samdf$SampleID) # TRUE

rownames(samdf) <- samdf$SampleID
keep.cols <- c("collection_date", "biome", "target_gene", "target_subfragment",
"host_common_name", "host_subject_id", "age", "sex", "body_product", "tot_mass",
"diet", "family_relationship", "genotype", "SampleID") 
samdf <- samdf[rownames(seqtabAll), keep.cols]

# Combine the meta data, seq, and taxonomy with phylogenetic tree
ps <- phyloseq(otu_table(seqtabNoC, taxa_are_rows=FALSE), 
               sample_data(samdf), 
               tax_table(taxTab),phy_tree(fitGTR$tree))
ps <- prune_samples(sample_names(ps) != "Mock", ps) # Remove mock sample
ps # This is the main object for downstream analysis

# save the tree object
# saveRDS(ps, file = file.path(wd_path,paste0("ps",".rds")))
```

## Filtering
We need to exclude toxonomy that is rare among samples

### Toxonomy filtering (Supervised filtering)
This filtering method is based on prior understanding of Toxonomy in our experiments. Therefore, the reference Toxonomy data set and the classification process should be reliable.
```{r filtering}
# use another more complete data set for the downstream analysis
ps_connect <-url("https://raw.githubusercontent.com/spholmes/F1000_workflow/master/data/ps.rds")
ps = readRDS(ps_connect)
ps
rank_names(ps)
table(tax_table(ps)[, "Phylum"], exclude = NULL)

# remove phylum that are not characterized
ps <- subset_taxa(ps, !is.na(Phylum) & !Phylum %in% c("", "uncharacterized"))
ps
```

We then calculate the prevalance of each Toxonomy in our experiment.
```{r toxonomy_prevalence}
# Compute prevalence of each feature, store as data.frame
prevdf = apply(X = otu_table(ps),
               MARGIN = ifelse(taxa_are_rows(ps), yes = 1, no = 2),
               FUN = function(x){sum(x > 0)})
# Add taxonomy and total read counts to this data.frame
prevdf = data.frame(Prevalence = prevdf,
                    TotalAbundance = taxa_sums(ps),
                    tax_table(ps))
plyr::ddply(prevdf, "Phylum", function(df1){cbind(mean(df1$Prevalence),sum(df1$Prevalence))})
```
Apparently Deinococcus-Thermus and Fusobacteria are rare Toxonomy among samples. We will filter them out.
```{r filtering}
# Define phyla to filter
filterPhyla = c("Fusobacteria", "Deinococcus-Thermus")
# Filter entries with unidentified Phylum.
ps1 = subset_taxa(ps, !Phylum %in% filterPhyla)
ps1
```

Checking the filtering result
```{r plot}
# Subset to the remaining phyla
prevdf1 = subset(prevdf, Phylum %in% get_taxa_unique(ps1, "Phylum"))
ggplot(prevdf1, aes(TotalAbundance, Prevalence / nsamples(ps),color=Phylum)) +
  # Include a guess for parameter
  geom_hline(yintercept = 0.05, alpha = 0.5, linetype = 2) +  geom_point(size = 2, alpha = 0.7) +
  scale_x_log10() +  xlab("Total Abundance") + ylab("Prevalence [Frac. Samples]") +
  facet_wrap(~Phylum) + theme(legend.position="none")
```

### Prevalance filtering (Unsupervised filtering)
This method does not required a prior understanding of Toxonomy in our experiment. This method exclude feature based on its prevalence.
```{r filtering}
# Define prevalence threshold as 5% of total samples
prevalenceThreshold = 0.05 * nsamples(ps)
prevalenceThreshold
# Execute prevalence filter, using `prune_taxa()` function
keepTaxa = rownames(prevdf1)[(prevdf1$Prevalence >= prevalenceThreshold)]
ps2 = prune_taxa(keepTaxa, ps)
ps2
```

## Agglomerate Toxonomy
We should also agglomerate data features corresponding to closely related Toxonomy. That could help us to reduce the functional redundancy in a microbial community.
```{r filtering}
# How many genera would be present after filtering?
length(get_taxa_unique(ps2, taxonomic.rank = "Genus"))
ps3 = tax_glom(ps2, "Genus", NArm = TRUE) # Generate a phyloseq object based on agglomerate by Genus

# We specify a tree height corresponding to the phylogenetic distance between features that should define their grouping
h1 = 0.4
ps4 = tip_glom(ps2, h = h1) # Generate a phyloseq object based on agglomerate by a fixed tree height
```

Plot the Tree (before and after aggregation)
```{r plot}
multiPlotTitleTextSize = 15
p2tree = plot_tree(ps2, method = "treeonly",
                   ladderize = "left",
                   title = "Before Agglomeration") +
  theme(plot.title = element_text(size = multiPlotTitleTextSize))
p3tree = plot_tree(ps3, method = "treeonly",
                   ladderize = "left", title = "By Genus") +
  theme(plot.title = element_text(size = multiPlotTitleTextSize))
p4tree = plot_tree(ps4, method = "treeonly",
                   ladderize = "left", title = "By Height") +
  theme(plot.title = element_text(size = multiPlotTitleTextSize))

# group plots together
grid.arrange(nrow = 1, p2tree, p3tree, p4tree)
```

## Abundance value transformation
We then transform the count value to the frequencies (or called relative abundance).

### Transform the data to relative abundance
```{r transform}
# Transform to relative abundance. Save as new object.
ps3ra = transform_sample_counts(ps3, function(x){x / sum(x)})
```

### Plot
We make the ggplot object first
```{r make_ggplot}
# Define the plot_abundance function
plot_abundance = function(physeq,title = "",
                          Facet = "Order", Color = "Phylum"){
  # Arbitrary subset, based on Phylum, for plotting
  p1f = subset_taxa(physeq, Phylum %in% c("Firmicutes"))
  mphyseq = psmelt(p1f)
  mphyseq <- subset(mphyseq, Abundance > 0)
  ggplot(data = mphyseq, aes(x = age, y = Abundance,
                              color = Color, fill = Color)) +
    geom_violin(fill = NA,aes(group = cut_interval(age, n=4))) +
    geom_point(size = 1, alpha = 0.3,
               position = position_jitter(width = 0.3)) +
    facet_wrap(facets = Facet) + scale_y_log10()+
    theme(legend.position="none")
}
```

Then plot
```{r plotting}
plotBefore = plot_abundance(ps3,"")
plotAfter = plot_abundance(ps3ra,"")
# Combine each plot into one graphic.
grid.arrange(nrow = 2,  plotBefore, plotAfter)
```

Another example
```{r plotting}
psOrd = subset_taxa(ps3ra, Order == "Lactobacillales")
plot_abundance(psOrd, Facet = "Genus", Color = NULL)
```